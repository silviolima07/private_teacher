import streamlit as st
import whisper
import tempfile
import os
from crewai import Agent, Task, Crew
from dotenv import load_dotenv
from gtts import gTTS  # Biblioteca para converter texto em Ã¡udio
from st_audiorec import st_audiorec  # Biblioteca para gravaÃ§Ã£o de Ã¡udio no Streamlit
from PIL import Image

#__import__('pysqlite3')
import sys
#sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

# Carregar variÃ¡veis de ambiente
load_dotenv()

# Definir modelo da GROQ
llm = "groq/llama3-8b-8192"

# Estado global para armazenar conversa
if "conversation_history" not in st.session_state:
    st.session_state.conversation_history = []

# FunÃ§Ã£o para processar Ã¡udio capturado
def process_audio_data(audio_data):
    # Criar arquivo temporÃ¡rio de Ã¡udio
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
        tmpfile.write(audio_data)
        audio_file = tmpfile.name
        #st.audio(audio_file)  # Reproduzir o Ã¡udio gravado

    # TranscriÃ§Ã£o do Ã¡udio
    model = whisper.load_model("base")
    result = model.transcribe(audio_file)
    transcribed_text = result["text"]

    st.session_state.conversation_history.append({"user": transcribed_text})
    st.success("ğŸ§ Audio -> Texto: Transcricao  concluida!")

    if transcribed_text.strip():
        send_to_agent()
        os.unlink(audio_file)
    else:
        st.error("NÃ£o foi possÃ­vel transcrever o Ã¡udio. Tente novamente.")

    os.unlink(audio_file)

# FunÃ§Ã£o para enviar conversa ao CrewAI
def send_to_agent():
    conversation_text = "\n".join(
        [f"UsuÃ¡rio: {msg['user']}" if 'user' in msg else f"Professor: {msg['bot']}" for msg in st.session_state.conversation_history]
    )

    teacher = Agent(
        role="English Teacher",
        goal="Ajude os alunos a aprender inglÃªs corrigindo seus erros e sugerindo melhorias.",
        backstory="Sou um professor paciente e experiente em ensinar inglÃªs para iniciantes.",
        verbose=True,
        allow_delegation=False,
        llm=llm
    )

    task = Task(
        description=f"Continue essa conversa:\n\n{conversation_text}\n\nResponda educadamente e de forma clara.",
        expected_output="Uma resposta coerente com o contexto, incluindo explicaÃ§Ãµes gramaticais se necessÃ¡rio.",
        agent=teacher
    )

    crew = Crew(agents=[teacher], tasks=[task])
    with st.spinner("ğŸ§‘â€ğŸ« Professor estÃ¡ pensando..."):
        response_obj = crew.kickoff()

    # Garantir que a resposta seja string pura
    response_text = str(response_obj).strip()  

    st.session_state.conversation_history.append({"bot": response_text})

    # Converter resposta do professor em Ã¡udio
    generate_audio(response_text)

# FunÃ§Ã£o para gerar e reproduzir Ã¡udio da resposta do professor
def generate_audio(text):
    st.write("Tacher speeking...")
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmpfile:
        tts = gTTS(text, lang="en")
        tts.save(tmpfile.name)
        audio_path = tmpfile.name

    # Exibir o player de Ã¡udio
    st.audio(audio_path, format="audio/mp3")

# Interface Streamlit
#st.title("ğŸ™ï¸ Chatbot Teacher - Fale e Aprenda InglÃªs")

html_page_title = """
<div style="background-color:black;padding=60px">
        <p style='text-align:center;font-size:60px;font-weight:bold; color:red'>ğŸ™ï¸ Chatbot Teacher </p>
</div>
"""               
st.markdown(html_page_title, unsafe_allow_html=True)

col1,col2 = st.columns(2)

with col2:
    # Usar st_audiorec para capturar Ã¡udio
    audio_data = st_audiorec()
    
with col1:
    st.image(Image.open('img/aprender.png'))    

    

# BotÃ£o para processar o Ã¡udio gravado
if audio_data is not None:
    #if st.button("â¹ï¸ Processar Ãudio"):
    #    process_audio_data(audio_data)
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmpfile:
        tmpfile.write(audio_data)
        audio_file = tmpfile.name
        #st.audio(audio_file)  # Reproduzir o Ã¡udio gravado

    # TranscriÃ§Ã£o do Ã¡udio
    model = whisper.load_model("base")
    result = model.transcribe(audio_file)
    transcribed_text = result["text"]

    st.session_state.conversation_history.append({"user": transcribed_text})
    st.success("ğŸ§ Audio -> Texto: Transcricao  concluida!")

    if transcribed_text.strip():
        send_to_agent()
    else:
        st.error("NÃ£o foi possÃ­vel transcrever o Ã¡udio. Tente novamente.")

    os.unlink(audio_file)
        
        
        
        

# Mostrar histÃ³rico da conversa
st.subheader("ğŸ“ HistÃ³rico da Conversa")
for msg in st.session_state.conversation_history:
    if "user" in msg:
        st.write(f"**ğŸ—£ï¸ VocÃª:** {msg['user']}")
    else:
        st.write(f"**ğŸ§‘â€ğŸ« Teacher:** {msg['bot']}")